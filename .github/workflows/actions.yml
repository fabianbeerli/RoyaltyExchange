name: Scrape Data, build and upload Model

on:
  push:
  workflow_dispatch:

jobs:
  build:
    runs-on: ubuntu-latest
    steps:

      - name: checkout repo content
        uses: actions/checkout@v3 # checkout the repository content to github runner

      - name: setup python
        uses: actions/setup-python@v4
        with:
          python-version: '3.12.1' # install the python version needed
          cache: 'pip'
          
      - name: install python packages
        run: pip install -r requirements.txt

      - name: Prepare Firefox and GeckoDriver
        uses: browser-actions/setup-firefox@latest
        
      - name: install geckodriver
        run: |
          wget https://github.com/mozilla/geckodriver/releases/download/v0.34.0/geckodriver-v0.34.0-linux64.tar.gz
          tar -xvzf geckodriver-v0.34.0-linux64.tar.gz
          chmod +x geckodriver
          sudo mv geckodriver /usr/local/bin/
          chmod +x /usr/local/bin/geckodriver # Ensure geckodriver is executable

      - name: scrape hikr data 
        working-directory: ./spider
        run: scrapy crawl gpx -s CLOSESPIDER_PAGECOUNT=50 -o file.jl

      - name: upload data to mongodb
        working-directory: spider/downloads
        run: python ./mongo_import.py -c tracks -i ../file.jl -u "${{secrets.MONGODB_URI}}"

      - name: build model
        working-directory: model
        run: python ./model.py -u "${{secrets.MONGODB_URI}}"

      - name: upload model
        working-directory: model
        run: python ./save.py -c "${{secrets.AZURE_STORAGE_CONNECTION_STRING}}"
